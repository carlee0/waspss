{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WASP Summer School 2020 \n",
    "# Gaussian Process Basics Lab \n",
    "\n",
    "### Objectives: \n",
    "1. Visualize 2D Gaussians and play with mean and covariance parameters\n",
    "2. Gaussian conditioning\n",
    "3. Visualize the alternative form of multivariate Gaussians\n",
    "4. Visualize covariance matrices with various kernels\n",
    "5. Implement Matern kernels\n",
    "6. Sample GPs\n",
    "\n",
    "### Prerequisites: \n",
    "In case you didn't go through the prerequisites of this module do it now: [Install](https://github.com/luinardi/hypermapper/wiki/Install-HyperMapper) Anaconda 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm \n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.stats import norm\n",
    "import math\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1 Gaussian distribution (5 minutes)\n",
    "Get familiar with 2D Gaussians. \n",
    "* Insert the mean vector and the covariance matrix (covariance needs to be symmetric positive definite)\n",
    "* Choose a number of samples to show\n",
    "* Plot\n",
    "* Repeat (until you get familiar with various $\\mathbf{\\mu}$ and $\\mathbf{\\Sigma}$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_gaussian(mu, Sigma, number_of_samples=0):\n",
    "    \"\"\" Plot a 2D Gaussian defined by mu and Sigma and draw number_of_samples samples from this distribution\n",
    "\n",
    "        Parameters:\n",
    "        mu: 2D mean vector\n",
    "        Sigma: 2x2 covariance matrix\n",
    "        number_of_samples: number of samples (>=0) to be visualized from a 2D Gaussian defined by mu and Sigma.\n",
    "\n",
    "        Returns:\n",
    "        Plots 2D Gaussian\n",
    "        \"\"\"\n",
    "\n",
    "    # Check input parameters\n",
    "    if len(mu) != 2 or len(Sigma) != 2 or len(Sigma[0]) !=2 or number_of_samples<0 or Sigma[0,1]!=Sigma[1,0]:\n",
    "        raise SystemExit(\"Input error.\")\n",
    "\n",
    "    # Set up the multivariate Gaussian\n",
    "    x1, x2 = np.mgrid[-3:3:.1, -3:3:.1] # 2D distribution over x1 and x2\n",
    "    pos = np.empty(x1.shape + (2,))     # Pack x1 and x2 into a single 2-dimensional array\n",
    "    pos[:, :, 0] = x1\n",
    "    pos[:, :, 1] = x2\n",
    "    gaussian = multivariate_normal(mu, Sigma)   # Create bivariate Gaussian distribution\n",
    "    y = gaussian.pdf(pos)                       # Probability density function evaluated on pos\n",
    "    samples = gaussian.rvs(number_of_samples)   # Sample the multivariate Gausssian pdf\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(5, 4.5))\n",
    "    ax.contourf(x1, x2, y, 10, cmap=cm.YlGnBu)    # Plot bivariate distribution\n",
    "    ax.plot(samples[:, 0], samples[:, 1], 'ro')   # Plot samples_multivariate\n",
    "\n",
    "    # Plot formatting\n",
    "    ax.set_xlabel('$x_1$', fontsize=16)\n",
    "    ax.set_ylabel('$x_2$', fontsize=16)\n",
    "    ax.axis([-3, 3, -3, 3])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mu = np.array([0., 0.]) # Mean vector. Example: [0., 0.]\n",
    "Sigma = np.array([      # Covariance matrix. Example: [[1., .4], [.4,  1.]]\n",
    "    [1., .6],\n",
    "    [.6,  1.]\n",
    "])\n",
    "number_of_samples = 2    # Example: number_of_samples = 10\n",
    "\n",
    "plot_2D_gaussian(mu, Sigma, number_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2 Gaussian conditioning (5 minutes)\n",
    "Get familiar with the conditioning property of Gaussian distributions. \n",
    "* Insert the mean vector and the covariance matrix (covariance needs to be symmetric positive definite)\n",
    "* Insert a conditioning value\n",
    "* Plot\n",
    "* Repeat (until you get familiar with Gaussian conditioning)\n",
    "\n",
    "Remember from the lecture that: \n",
    "### $$p({\\color{blue}{\\mathbf{x_1}}}, {\\color{red}{\\mathbf{x_2}}}) = \\mathcal{N}\\begin{pmatrix}\\begin{pmatrix} \\mathbf{a}\\\\\\mathbf{b} \\end{pmatrix}, \\begin{pmatrix} \\mathbf{A}&\\mathbf{B}\\\\\\mathbf{B}^T&\\mathbf{C}\\end{pmatrix}\\end{pmatrix} $$\n",
    "\n",
    "### $$\\Longrightarrow  p({\\color{blue}{\\mathbf{x_1}}}| {\\color{red}{\\mathbf{x_2}}}) = \\mathcal{N}(\\mathbf{a} + \\mathbf{BC^{-1}}({\\color{red}{\\mathbf{x_2}}} - \\mathbf{b}), \\mathbf{A} - \\mathbf{BC^{-1}B^\\top}) $$\n",
    "\n",
    "### $$\\Longrightarrow  p({\\color{red}{\\mathbf{x_2}}}| {\\color{blue}{\\mathbf{x_1}}}) = \\mathcal{N}(\\mathbf{b} + \\mathbf{B^\\top A^{-1}}({\\color{blue}{\\mathbf{x_1}}} - \\mathbf{a}), \\mathbf{C} - \\mathbf{B^\\top A^{-1}B}) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2D_gaussian_conditional_distribution(mu, Sigma, x1_conditioning, number_of_samples=0):\n",
    "    \"\"\" Conditioning of a bivariate Gaussian defined by mu and Sigma.\n",
    "\n",
    "        Parameters:\n",
    "        mu: 2D mean vector\n",
    "        Sigma: 2x2 covariance matrix under the form of\n",
    "               Sigma = (A   B)\n",
    "                       (B^T C)\n",
    "        number_of_samples: number of samples (>=0) to be visualized from the 1D Gaussian defined by mu, Sigma and x1_conditioning.\n",
    "\n",
    "        Returns:\n",
    "        Visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 5))\n",
    "    gs = gridspec.GridSpec(1, 2, width_ratios=[2, 1])\n",
    "    ax1 = plt.subplot(gs[0]) # Left plot\n",
    "    sns.set_style('darkgrid')\n",
    "    ax2 = plt.subplot(gs[1]) # Right plot\n",
    "\n",
    "    ######### Left plot\n",
    "    x1, x2 = np.mgrid[-3:3:.1, -3:3:.1]  # 2-dimensional distribution over x1 and x2\n",
    "    pos = np.empty(x1.shape + (2,))      # Pack x1 and x2 into a single 2-dimensional array\n",
    "    pos[:, :, 0] = x1\n",
    "    pos[:, :, 1] = x2\n",
    "    gaussian = multivariate_normal(mu, Sigma)  # Create bivariate Gaussian distribution\n",
    "    y = gaussian.pdf(pos)                      # Probability density function evaluated on pos\n",
    "\n",
    "    con = ax1.contourf(x1, x2, y, 10, cmap=cm.YlGnBu)               # Plot bivariate distribution\n",
    "    ax1.plot([x1_conditioning, x1_conditioning], [-3, 3], 'b--')    # Conditioning line\n",
    "\n",
    "    # Plot formatting\n",
    "    ax1.set_xlabel('$x_1$', fontsize=16)\n",
    "    ax1.set_ylabel('$x_2$', fontsize=16)\n",
    "    ax1.axis([-3, 3, -3, 3])\n",
    "    ax1.spines['top'].set_visible(False)\n",
    "    ax1.spines['right'].set_visible(False)\n",
    "\n",
    "    ######### Right plot\n",
    "    A = Sigma[0, 0]\n",
    "    C = Sigma[1, 1]\n",
    "    B = Sigma[0, 1]\n",
    "    BT = Sigma[1, 0]\n",
    "    a = mu[0]\n",
    "    b = mu[1]\n",
    "    conditional_mu = b + BT * (1 / A) * (x1_conditioning - a)   # Calculate conditional mu x2|x1\n",
    "    conditional_sigma = C - (BT * (1 / A) * B)                  # Calculate conditional Sigma x2|x1\n",
    "\n",
    "    x2x1 = np.linspace(-3, 3, num=100)\n",
    "    F_univariate = norm(conditional_mu, conditional_sigma)  # Create univariate Gaussian distribution\n",
    "    px2x1 = F_univariate.pdf(x2x1)                          # Probability density function evaluated on pos\n",
    "    samples_univariate = F_univariate.rvs(number_of_samples)# Sample the univariate Gausssian pdf\n",
    "\n",
    "    ax2.plot(px2x1, x2x1, 'b--', label=f'$p(x_2|x_1={x1_conditioning})$') # Plot univariate distribution x2|x1\n",
    "    ax2.plot(np.zeros(len(samples_univariate)), samples_univariate, 'ro') # Plot samples_univariate\n",
    "\n",
    "    # Plot formatting\n",
    "    ax2.legend(loc=0)\n",
    "    ax2.set_ylim(-3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.array([0., 0.]) # Mean vector\n",
    "Sigma = np.array([      # Covariance matrix\n",
    "    [1, .4],\n",
    "    [.4,  1]\n",
    "])\n",
    "x1_conditioning = 1\n",
    "number_of_samples = 10\n",
    "plot_2D_gaussian_conditional_distribution(mu, Sigma, x1_conditioning, number_of_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3 Visualize Covariance Functions (10 minutes)\n",
    "Get familiar with various covariance functions and their hyperparameters.\n",
    "* Pick the parameters\n",
    "* Plot\n",
    "* Repeat (until you get familiar with the kernel global properties) \n",
    "\n",
    "#### Squared Exponential: $K(x_1, x_2) = \\sigma^2 e^{-\\frac{1}{2l^2}(x_1 - x_2)^2} $\n",
    "\n",
    "#### Brownian Motion: $K(x_1, x_2) = \\sigma^2 e^{-\\frac{1}{2l^2}|x_1 - x_2|} $\n",
    "\n",
    "#### Periodic: $K(x_1, x_2) = \\sigma^2 \\cos{(\\omega(x_1 - x_2))}e^{-\\frac{1}{2l^2}(x_1 - x_2)^2}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mean_and_covariance(kernel=\"se\", N=10, sigma=1., l=2.5):\n",
    "    \"\"\" Creates a mean vector and a covariance matrix of size NxN for an input space in in [0, 10].\n",
    "        This method uses the kernel specified by the input parameter \"kernel\" to generate the covariance matrix.\n",
    "        Input parameters:\n",
    "        :param kernel: the kernel used to generate the covariance function. Options are: \"se\", \"bm\" and \"periodic\".\n",
    "        :param N: number of entries in the covariance matrix NxN.\n",
    "        :param sigma: the sigma hyperparameter of the kernel.\n",
    "        :param l: the l hyperparameter of the kernel.\n",
    "\n",
    "        Returns:\n",
    "        Mean vector and covariance matrix of size NxN.\n",
    "    \"\"\"\n",
    "    # Check input parameters\n",
    "    if N < 0 or N > 1000 or sigma < 0. or l < 0.:\n",
    "        raise SystemExit(\"Input error.\")\n",
    "        \n",
    "    input_space = 10.0\n",
    "    step = input_space/N\n",
    "    mu = np.zeros(N)\n",
    "    Sigma = np.zeros((N, N))\n",
    "    x1 = 0.\n",
    "    for i in range(N):\n",
    "        x2 = 0.\n",
    "        for j in range(N):\n",
    "            if kernel == \"se\":\n",
    "                Sigma[i, j] = (sigma**2.)*math.exp((-1/(2*(l**2)))*(x1-x2)**2)\n",
    "            elif kernel == \"bm\":\n",
    "                Sigma[i, j] = (sigma ** 2.) * math.exp((-1 / (2 * (l ** 2))) * abs(x1 - x2))\n",
    "            elif kernel == \"periodic\":\n",
    "                omega = 1.2\n",
    "                Sigma[i, j] = (sigma**2.)*math.cos(omega*(x1-x2))*math.exp((-1/(2*(l**2)))*(x1-x2)**2)\n",
    "            else:\n",
    "                raise SystemExit(\"I cannot recognize the kernel requested. Exit.\")\n",
    "            x2 = x2 + step\n",
    "        x1 = x1 + step\n",
    "    return(mu, Sigma)\n",
    "\n",
    "def plot_covariance_matrix(Sigma):\n",
    "    \"\"\"     Plot Sigma matrix using colors\n",
    "            Input parameter:\n",
    "            :param Sigma: the Sigma covariance matrix to be visualized.\n",
    "\n",
    "            Returns:\n",
    "            Plot the covariance matrix. \n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.matshow(Sigma, cmap='jet')\n",
    "    plt.xticks([], [])\n",
    "    plt.yticks([], [])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one of the following kernels: \"se\", \"bm\", \"periodic\"\n",
    "kernel = \"se\" \n",
    "\n",
    "# Pick vertical and horizontal scale hyperparameters\n",
    "sigma = 1.\n",
    "l = 2.5\n",
    "\n",
    "# Pick the size of the covariance matrix \n",
    "# The space is fixed to x=[0, 10] but you can vary the amount of points in that interval (max value is 1000)\n",
    "number_of_x_points = 100\n",
    "\n",
    "mu, Sigma = create_mean_and_covariance(kernel, number_of_x_points , sigma, l)\n",
    "plot_covariance_matrix(Sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #4 Implement Matern Covariance Functions (10 minutes)\n",
    "It is possible that the most interesting covariance functions in ML are given by the Matern class of covariance functions (see [Rasmussen and Williams, 2006] Sec. 4.2 for more information) named after Bertil Matérn. Special cases of the Matérn covariance function are the Squared exponential and the Exponential (Ornstein-Uhlenbeck) covariance functions. \n",
    "\n",
    "Of particular interest for the ML community are the Matern32 and Matern52 instances that are given by: \n",
    "\n",
    "### Matern32: \n",
    "## $$\\sigma^2 \\begin{pmatrix} 1 + \\frac{\\sqrt{3}|x_1 - x_2|}{l}\\end{pmatrix}e^{-\\frac{\\sqrt{3}|x_1 - x_2|}{l}}$$\n",
    " \n",
    "### Matern52: \n",
    "## $$\\sigma^2 \\begin{pmatrix} 1 + \\frac{\\sqrt{5}|x_1 - x_2|}{l} + \\frac{5(x_1 - x_2)^2}{3l^2}\\end{pmatrix}e^{-\\frac{\\sqrt{5}|x_1 - x_2|}{l}}$$\n",
    " \n",
    "\n",
    "\n",
    "* Implement Matern32 and Matern52 covariance functions in the code above.\n",
    "* Plot Matern32 and Matern52 multiple times.  \n",
    "* Vary the hyperparameters of the Matern covariance function. \n",
    "* Repeat \n",
    "* What do you oberve? How different are they? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #5 Alternative Representation of Multi-dimensional Gaussians (10 minutes)\n",
    "In this section we sample a GP.\n",
    "\n",
    "* Initialize the vectors for the conditioning. \n",
    "* Plot a sample of the GP.\n",
    "* Execute the same code several times and observe how the plot changes. \n",
    "* Repeat (ideas: change the kernel, change the hyperparameters l and sigma, run the Matern kernels).\n",
    "* What happens to the discrete form of the GP sample when you increase the number of points to 1,000?\n",
    "* Study the code (ideas: what is the swapping of variables for?).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional(mu, Sigma, x_conditioning):\n",
    "    \"\"\" This is an utility method used in the main method.\n",
    "        Conditioning of a Gaussian defined by mu and Sigma. \n",
    "        This method is more general than the previous one because it works for an arbitrary number of variables. \n",
    "\n",
    "        Parameters:\n",
    "        :param mu: 2D mean vector.\n",
    "        :param Sigma: 2x2 covariance matrix under the form of.\n",
    "               Sigma = (XX XY)\n",
    "                       (YX YY)\n",
    "\n",
    "        Returns:\n",
    "        A new mu and Sigma that are the result of the conditioning operation.\n",
    "    \"\"\"\n",
    "    if len(x_conditioning) == 0:\n",
    "        return(mu, Sigma)\n",
    "\n",
    "    indices_conditioning = np.array([i for i in range(0, len(x_conditioning))]) # Using list comprehension\n",
    "    indices_non_conditioning = np.array([i for i in range(len(x_conditioning), len(mu))])\n",
    "\n",
    "    XX = Sigma[np.ix_(indices_conditioning, indices_conditioning)] # ix_ selects the elements that are the cartesian product of the two arrays in argument\n",
    "    YY = Sigma[np.ix_(indices_non_conditioning, indices_non_conditioning)]\n",
    "    XY = Sigma[np.ix_(indices_conditioning, indices_non_conditioning)]\n",
    "    YX = XY.T\n",
    "\n",
    "    mu_y = mu[np.ix_(indices_non_conditioning)]\n",
    "    mu_x = mu[np.ix_(indices_conditioning)]\n",
    "\n",
    "    conditional_mu = mu_y + np.linalg.inv(XX).dot(YX.T).T.dot(x_conditioning - mu_x)\n",
    "    conditional_Sigma = YY - YX.dot(np.linalg.inv(XX).dot(XY))\n",
    "    return (conditional_mu, conditional_Sigma)\n",
    "\n",
    "\n",
    "def bubble_swap_variables(mu, Sigma, x_conditioning, x_conditioning_indices):\n",
    "    \"\"\" This is an utility method used in the main method.\n",
    "        It computes the swap of the Gaussian variables (rearrange the variables) in the mu and Sigma matrices so that\n",
    "        we can condition wrt arbitrary variables.\n",
    "\n",
    "        Parameters:\n",
    "        :param mu: mean vector.\n",
    "        :param Sigma: covariance matrix.\n",
    "        :param x_conditioning: a list of the conditioning values of the multivariate Gaussian.\n",
    "        This vector has to have the same size as x_conditioning_indices.\n",
    "        Example 1, no conditioning: []\n",
    "        Example 2, conditioning on 3 variables: [1, 1.4, 0.9]\n",
    "\n",
    "        :param x_conditioning_indices: the x variable indices of the conditioning variables.\n",
    "        This indicates wrt what Gaussian variables we are conditioning.\n",
    "        This vector has to have the same size as x_conditioning.\n",
    "        Example 1, no conditioning: []\n",
    "        Example 2, conditioning on 3 variables: [5, 12, 35]\n",
    "\n",
    "        Returns:\n",
    "        A new mu and Sigma with the conditional variables swapped (moved at the top left corner).\n",
    "    \"\"\"\n",
    "\n",
    "    tmp_Sigma = Sigma.copy()\n",
    "    tmp_mu = mu.copy()\n",
    "\n",
    "    if len(x_conditioning) > 0:\n",
    "        for i in range(len(x_conditioning)):\n",
    "            j = x_conditioning_indices[i]\n",
    "            for count in range(j, i, -1):\n",
    "                # Swapping backward all variables to send the conditional variables to the upper left corner of the\n",
    "                # covariance matrix, so that we can use the conditioning formula introduced in the slides.\n",
    "                tmp_Sigma, tmp_mu = swap_variables(tmp_mu, tmp_Sigma, count, count - 1)\n",
    "    return tmp_mu, tmp_Sigma\n",
    "\n",
    "\n",
    "def swap_variables(mu, Sigma, i, j):\n",
    "    \"\"\" This is an utility method in the bubble_swap_variables method.\n",
    "        It computes the swap of two Gaussian variables (rearrange the variables) in the mu and Sigma matrices.\n",
    "        The method uses the idea of swapping rows and columns to achieve the swap. \n",
    "        \n",
    "        Parameters:\n",
    "        :param mu: mean vector.\n",
    "        :param Sigma: covariance matrix.\n",
    "        :param i: source index.  \n",
    "        :param j: destination index.\n",
    "        \n",
    "        Returns:\n",
    "        A new mu and Sigma with the i and j variables swapped.\n",
    "        \"\"\"\n",
    "    Sigma[[i, j]] = Sigma[[j, i]]  # Swap rows of Sigma: j -> i and i -> j\n",
    "    Sigma = Sigma.T\n",
    "    Sigma[[i, j]] = Sigma[[j, i]]  # Swap columns of Sigma: j -> i and i -> j\n",
    "    Sigma = Sigma.T\n",
    "    mu[[i, j]] = mu[[j, i]]  # Swap elements of mu: j -> i and i -> j\n",
    "    return Sigma, mu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_GP(mu, Sigma, x_conditioning, x_conditioning_indices):\n",
    "    \"\"\" Plot a GP sample.\n",
    "\n",
    "        Parameters:\n",
    "        :param mu: mean vector.\n",
    "        :param Sigma: covariance matrix.\n",
    "        :param x_conditioning: a list of the conditioning values of the multivariate Gaussian.\n",
    "        This vector has to have the same size as x_conditioning_indices.\n",
    "        Example 1, no conditioning: []\n",
    "        Example 2, conditioning on 3 variables: [1, 1.4, 0.9]\n",
    "\n",
    "        :param x_conditioning_indices: the x variable indices of the conditioning variables.\n",
    "        This indicates wrt what Gaussian variables we are conditioning.\n",
    "        This vector has to have the same size as x_conditioning.\n",
    "        Example 1, no conditioning: []\n",
    "        Example 2, conditioning on 3 variables: [5, 12, 35]\n",
    "\n",
    "        Returns:\n",
    "        GP sample visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    total_points = len(mu)\n",
    "    map_to_fixed_x_interval = 10. / total_points\n",
    "\n",
    "    if len(x_conditioning) != len(x_conditioning_indices):\n",
    "        raise SystemExit(\"Error: size of the arrays describing the conditional distributions have to be the same size.\")\n",
    "    for i in range(len(x_conditioning_indices)):\n",
    "        if x_conditioning_indices[i] >= len(mu):\n",
    "            raise SystemExit(\"Conditioning indices out of range. Rewrite your vectors x_conditioning and x_conditioning_indices. \")\n",
    "            \n",
    "    # Compute the non-conditioning indices\n",
    "    x_non_conditioning_indices = np.array([])  # For the conditional distribution variable indices\n",
    "    for i in range(len(mu)):\n",
    "        if i not in x_conditioning_indices:\n",
    "            x_non_conditioning_indices = np.append(x_non_conditioning_indices, i)\n",
    "\n",
    "    tmp_mu, tmp_Sigma = bubble_swap_variables(mu, Sigma, x_conditioning, x_conditioning_indices)  # Arrange variables to be able to compute the conditional Gaussian\n",
    "    mu_conditional, Sigma_conditional = conditional(tmp_mu, tmp_Sigma, x_conditioning)            # Compute conditional Gaussian\n",
    "\n",
    "    F_multivariate = multivariate_normal(mu_conditional, Sigma_conditional, allow_singular=True) # Create multivariate Gaussian distribution on the conditional mu and Sigma\n",
    "    # Sample the multivariate Gausssian, i.e., sample the Gaussian process\n",
    "    if len(mu_conditional) == 1:\n",
    "        sample = [F_multivariate.rvs(1)]\n",
    "    else:\n",
    "        sample = F_multivariate.rvs(1)\n",
    "\n",
    "    # This block plots the new visualization with two points connected by a bar\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(x_conditioning_indices * map_to_fixed_x_interval, x_conditioning, 'rx', markeredgewidth=4, ms=10) # Plot conditioning points\n",
    "    ax.plot(x_non_conditioning_indices * map_to_fixed_x_interval, sample, 'ko', ms=2)  # Plot samples_multivariate\n",
    "\n",
    "    # Plot formatting\n",
    "    ax.set_xlabel('$x$', fontsize=30)\n",
    "    ax.set_ylabel('$y$', fontsize=30)\n",
    "    ax.axis([-1, 11, -3, 3])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_x_points = 100              # Pick the number of points on the x axis (this corresponds to the size of your covariance matrix). The space is fixed to x=[0, 10] but you can vary the amount of points in that interval\n",
    "x_conditioning = np.array([])         # For the conditional distribution\n",
    "x_conditioning_indices = np.array([]) # For the conditional distribution variable indices\n",
    "\n",
    "# Example 2: \n",
    "# number_of_x_points = 10\n",
    "# x_conditioning = np.array([])         # For the conditional distribution\n",
    "# x_conditioning_indices = np.array([]) # For the conditional distribution variable indices\n",
    "\n",
    "# Example 3: \n",
    "# number_of_x_points = 1000\n",
    "# x_conditioning = np.array([0.5])         # For the conditional distribution\n",
    "# x_conditioning_indices = np.array([10])  # For the conditional distribution variable indices. The values have to be <= than number_of_x_points\n",
    "\n",
    "# Example 4: \n",
    "# number_of_x_points = 100\n",
    "# x_conditioning = np.array([1., 1.4, 0.5, 1.])          # For the conditional distribution\n",
    "# x_conditioning_indices = np.array([10, 15, 60, 70]) # For the conditional distribution variable indices\n",
    "\n",
    "# Example 5: \n",
    "# number_of_x_points = 1000\n",
    "# x_conditioning = np.array([1., 1.4, 0.5, 1.])          # For the conditional distribution\n",
    "# x_conditioning_indices = np.array([10, 150, 600, 700]) # For the conditional distribution variable indices\n",
    "\n",
    "mu, Sigma = create_mean_and_covariance(\"se\", number_of_x_points)\n",
    "sample_GP(mu, Sigma, x_conditioning, x_conditioning_indices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #6 Plot GP Regression (5 minutes)\n",
    "In this section we plot the GP regression. \n",
    "\n",
    "* Initialize the vectors for the conditioning. \n",
    "* Plot.\n",
    "* Repeat (ideas: change the kernel, change the hyperparameters l and sigma, run the Matern kernels).\n",
    "* Study the code.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_GP_mean_and_std(mu, Sigma, x_conditioning, x_conditioning_indices):\n",
    "    \"\"\" Plot the GP mean and 2 Sigma.\n",
    "\n",
    "                    Parameters:\n",
    "                    :param mu: mean vector.\n",
    "                    :param Sigma: covariance matrix.\n",
    "                    :param x_conditioning: a list of the conditioning values of the multivariate Gaussian.\n",
    "                    This vector has to have the same size as x_conditioning_indices.\n",
    "                    Example 1, no conditioning: []\n",
    "                    Example 2, conditioning on 3 variables: [1, 1.4, 0.9]\n",
    "\n",
    "                    :param x_conditioning_indices: the x variable indices of the conditioning variables.\n",
    "                    This indicates wrt what Gaussian variables we are conditioning.\n",
    "                    This vector has to have the same size as x_conditioning.\n",
    "                    Example 1, no conditioning: []\n",
    "                    Example 2, conditioning on 3 variables: [5, 12, 35]\n",
    "\n",
    "                    Returns:\n",
    "                    GP visualization.\n",
    "            \"\"\"\n",
    "\n",
    "    if len(x_conditioning) != len(x_conditioning_indices):\n",
    "        raise SystemExit(\"Error: size of the arrays describing the conditional distributions have to be the same size.\")\n",
    "    for i in range(len(x_conditioning_indices)):\n",
    "        if x_conditioning_indices[i] >= len(mu):\n",
    "            raise SystemExit(\"Conditioning indices out of range. Rewrite your vectors x_conditioning and x_conditioning_indices. \")\n",
    "\n",
    "    total_points = len(mu)\n",
    "    map_to_fixed_x_interval = 10. / total_points\n",
    "\n",
    "    tmp_mu, tmp_Sigma = bubble_swap_variables(mu, Sigma, x_conditioning, x_conditioning_indices) # Arrange variables to be able to compute the conditional Gaussian\n",
    "    mu_conditional, Sigma_conditional = conditional(tmp_mu, tmp_Sigma, x_conditioning) # Compute conditional Gaussian\n",
    "\n",
    "    all_indices_x = np.zeros(len(mu))\n",
    "    all_indices_2_sigma_upper_bound_x = np.zeros(len(mu))\n",
    "    all_indices_2_sigma_lower_bound_x = np.zeros(len(mu))\n",
    "    all_indices_y = np.zeros(len(mu))\n",
    "    xi_conditioning = 0\n",
    "    xi_sample = 0\n",
    "    xi = 0.\n",
    "    step = 10. / total_points  # The x axis is in the interval of [0, 10]\n",
    "    for i in range(0, total_points, 1):\n",
    "        all_indices_x[i] = xi\n",
    "        if i in x_conditioning_indices:\n",
    "            all_indices_y[i] = x_conditioning[xi_conditioning]\n",
    "            all_indices_2_sigma_upper_bound_x[i] = all_indices_y[i]\n",
    "            all_indices_2_sigma_lower_bound_x[i] = all_indices_y[i]\n",
    "            xi_conditioning = xi_conditioning + 1\n",
    "        else:\n",
    "            all_indices_y[i] = mu_conditional[xi_sample]\n",
    "            all_indices_2_sigma_upper_bound_x[i] = all_indices_y[i] + 2*Sigma_conditional[xi_sample, xi_sample]\n",
    "            all_indices_2_sigma_lower_bound_x[i] = all_indices_y[i] - 2*Sigma_conditional[xi_sample, xi_sample]\n",
    "            xi_sample = xi_sample + 1\n",
    "        xi = xi + step\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    ax.plot(x_conditioning_indices * map_to_fixed_x_interval, x_conditioning, 'rx', markeredgewidth=4, ms=10)  # Plot conditioning points\n",
    "    ax.plot(all_indices_x, all_indices_y, 'b', alpha=.6, linewidth=1)  # Plot mean\n",
    "    plt.fill_between(all_indices_x, all_indices_2_sigma_lower_bound_x, all_indices_2_sigma_upper_bound_x, color=\"#CCCCFB\") # Plot 2 sigma\n",
    "\n",
    "    # Plot formatting\n",
    "    ax.set_xlabel('$x$', fontsize=30)\n",
    "    ax.set_ylabel('$y$', fontsize=30)\n",
    "    ax.axis([-1, 10, -3, 3])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_x_points = 10               # Pick the number of points on the x axis (this corresponds to the size of your covariance matrix). The space is fixed to x=[0, 10] but you can vary the amount of points in that interval\n",
    "x_conditioning = np.array([])         # For the conditional distribution\n",
    "x_conditioning_indices = np.array([]) # For the conditional distribution variable indices\n",
    "\n",
    "# Example 2: \n",
    "# number_of_x_points = 100\n",
    "# x_conditioning = np.array([0.5])         # For the conditional distribution\n",
    "# x_conditioning_indices = np.array([10])  # For the conditional distribution variable indices. The values have to be <= than number_of_x_points\n",
    "\n",
    "# Example 3: \n",
    "# number_of_x_points = 1000\n",
    "# x_conditioning = np.array([1., 1.4, 0.5, 1.])           # For the conditional distribution\n",
    "# x_conditioning_indices = np.array([10, 150, 600, 700])  # For the conditional distribution variable indices\n",
    "\n",
    "mu, Sigma = create_mean_and_covariance(\"se\", number_of_x_points)\n",
    "plot_GP_mean_and_std(mu, Sigma, x_conditioning, x_conditioning_indices)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
